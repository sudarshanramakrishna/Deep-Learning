{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (2.9.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: packaging in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.1)\n",
      "Installing collected packages: keras, flatbuffers, tensorflow-estimator, tensorboard\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.1.21\n",
      "    Uninstalling flatbuffers-23.1.21:\n",
      "      Successfully uninstalled flatbuffers-23.1.21\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n",
      "Successfully installed flatbuffers-1.12 keras-2.9.0 tensorboard-2.9.1 tensorflow-estimator-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <7070F2EA-8BCD-342E-ACDE-1F7C9F79DB56> /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/context.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coordination_config_pb2\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewriter_config_pb2\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/pywrap_tfe.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tfe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <7070F2EA-8BCD-342E-ACDE-1F7C9F79DB56> /Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/lib/python3.9/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/shreyanthhg/opt/anaconda3/envs/Tensorflow/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f44bd61-891a-4907-9ad4-4b24e2a476de",
    "_uuid": "226c6831972f96b5d8b50b66a6ff517c175b3e3b"
   },
   "outputs": [],
   "source": [
    "wbcd = pd.read_csv(\"data.csv\")\n",
    "wbcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4478f2f7-c82d-4b1d-8cc3-3a3d300c66f1",
    "_uuid": "5904e176a7d70ca730bafc6eacbe2d8e4ab693ac"
   },
   "outputs": [],
   "source": [
    "print(\"This WBCD dataset has\",wbcd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9536eacc-1a47-4633-b2e0-7d59860f42c7",
    "_uuid": "470e19dc549f573e737499d6a01be35d630c41b1"
   },
   "source": [
    "## Eliminate NaN value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5cfd1f39-8e74-4151-a117-d989fb2c8eaa",
    "_uuid": "7139966be0eae747e222b64fe0080d893c7a62a4"
   },
   "outputs": [],
   "source": [
    "wbcd = wbcd.iloc[:,:-1]\n",
    "print(\"This WBCD dataset has\",wbcd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa40b614-5d70-492e-a672-de808a12dcde",
    "_uuid": "4b3285686b3d66efcf5d5441be5ebf4eeb695c3b"
   },
   "source": [
    "## Summary the Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52ad3062-d000-49c5-94a7-4ad80c3a25de",
    "_uuid": "a8d564395cfb9b4b6c2758d37546a2d4074906f5"
   },
   "outputs": [],
   "source": [
    "wbcd.diagnosis.value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5460d21-3fc8-4e6d-ba23-acf4b0fdb354",
    "_uuid": "99491c255fb20c56cf862fb91fbe39830b9cff49"
   },
   "source": [
    "## Correlation Plot of 30 features\n",
    "except **id, diagnosis** columns => wbcd.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d89200b-ab00-4a5d-b94b-9fac3ac11fc6",
    "_uuid": "5e640fffd0e3e9ade799a75d3ac417d4a894916e"
   },
   "outputs": [],
   "source": [
    "corr = wbcd.iloc[:,2:].corr()\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 8},\n",
    "            cmap = colormap, linewidths=0.1, linecolor='white')\n",
    "plt.title('Correlation of WBCD Features', y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb7abe15-91ec-455c-9f06-488310ae10ef",
    "_uuid": "fd8c5caefa7ef7df8c9cfbe7c2fe5cfc047e1290"
   },
   "source": [
    "---\n",
    "\n",
    "# Preparing Data for machine learning\n",
    "## Divide \"WBCD data\" into Train(70%) / Test data(30%)\n",
    "Divide the data into two(train/test) to see the predictive power of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "010c6214-6da0-4a5c-9d0f-f5bf6a992790",
    "_uuid": "c7aa69db4e553eab98f8be59cbf1731746164b94"
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(wbcd, test_size=0.3, random_state=42)\n",
    "print(\"Training Data :\",train.shape)\n",
    "print(\"Testing Data :\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3afd3829-911e-4ab3-bbee-a058580a7345",
    "_uuid": "46e2739a863816cf2e55cded57836bf50d6385a8"
   },
   "source": [
    "## Drop ID column\n",
    "* Save the **ID** column for later combination(results).\n",
    "* Drop the **ID** column in train, test datasets, because it's unnecessary for model learning predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c4466ae-c775-4eaa-99e2-ae81a6f55f89",
    "_uuid": "d6d0f79538cf52db3322f311242d85447d7e0646"
   },
   "outputs": [],
   "source": [
    "train_id = train['id']\n",
    "test_id = test['id']\n",
    "\n",
    "train_data = train.iloc[:,1:]\n",
    "test_data = test.iloc[:,1:]\n",
    "\n",
    "print(\"Training Data :\",train_data.shape)\n",
    "print(\"Testing Data :\",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bfeffbae-bf0b-4ed9-880d-28b840bc57fb",
    "_uuid": "bb47e8bb957d9eb07332f7f58e9e3dbf52e8d1dd"
   },
   "source": [
    "## Seperate x:Feature data(30) / y:Result data(1)\n",
    "Seperate by **x_data, y_data**\n",
    "* x_data : columns(features to predict **diagnosis**) for training. (eliminate diagnosis)\n",
    "* y_data : columns for comparing with predictions results. (need original diagnosis)\n",
    "\n",
    "###  Normalize x_data values for better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62fd770f-f0ed-41da-95fe-2f96c4014024",
    "_uuid": "e697e0b948b2549d9320dd5af6220e6fd57b8b26"
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_x = train_data.iloc[:,1:]\n",
    "train_x = MinMaxScaler().fit_transform(train_x)\n",
    "print(\"Training Data :\", train_x.shape)\n",
    "\n",
    "# Testing Data\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_x = MinMaxScaler().fit_transform(test_x)\n",
    "print(\"Testing Data :\", test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd11f718-18bb-4ff2-9892-bbf3ee221945",
    "_uuid": "cf139095fcb3ed9a2073ebbb2da5be2fadcf562d"
   },
   "source": [
    "### Change Results(diagnosis) format : String -> Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb419590-3d9c-47ff-9df2-56ccdd7eacf7",
    "_uuid": "eda3af7c8969e6b2853f2b6380d48a51aa5a7b05"
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_y = train_data.iloc[:,:1]\n",
    "train_y[train_y=='M'] = 0\n",
    "train_y[train_y=='B'] = 1\n",
    "print(\"Training Data :\", train_y.shape)\n",
    "\n",
    "# Testing Data\n",
    "test_y = test_data.iloc[:,:1]\n",
    "test_y[test_y=='M'] = 0\n",
    "test_y[test_y=='B'] = 1\n",
    "print(\"Testing Data :\", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa3ff52a-9d01-46af-ba41-945d6f960f3b",
    "_uuid": "997e336dc4501dc0dcb5db2c1f7fcac363b381f3"
   },
   "source": [
    "---\n",
    "\n",
    "# 6. Make ANN-SLP Model\n",
    "## 6-1) Make \"Placeholder\" for dinamic variable allocation\n",
    "Placeholder is one of the function in tensorflow.\n",
    "It is a space to put and change values while the program is running.\n",
    "* for X, a place must have 30 columns, since wbcd data has 30 features.\n",
    "* for Y, a place must have 1 columns, since the results has 1 outcome.\n",
    "* If you see the row \"None\", it means it has no size limits. (You can write -1 instead of \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2f628ba-b54f-4606-88b3-a94e8d04abfc",
    "_uuid": "203de4b9aea972e31c4887e81b69011e978b4ae2"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None,30])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8b4db30e-6d9a-4218-a13c-77646f448e06",
    "_uuid": "6150a33f862340ace07c778141028d9e7ef43c9a"
   },
   "source": [
    "## 6-2) Make Weight, Bias value with randomly\n",
    "* W(weight) : why **[30,1]**?  16 for 16 features, 1 for 1 Outcome(results).\n",
    "* P(weight): why **[10,1]**? 10 for 10 PCA features, 1 for 1 Outcome(results).\n",
    "* b(bias) : why **[1]**?  outcome has 1 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1f84757-a576-4e5b-8906-bce6dba3c84c",
    "_uuid": "e8791b6931c8197198f85a99f20e777697774906"
   },
   "outputs": [],
   "source": [
    "# weight\n",
    "W = tf.Variable(tf.random_normal([30,1], seed=0), name='weight')\n",
    "\n",
    "# bias\n",
    "b = tf.Variable(tf.random_normal([1], seed=0), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "97f607ce-213d-4e4a-a8e9-cc30c47d68a1",
    "_uuid": "a16646d548cc2bf15303c815a12627e326fb7d7c"
   },
   "source": [
    "## 6-3) Make Output Results\n",
    " * **Output = Weight * Input + Bias**\n",
    " * tf.matmul() : for array multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56416585-56a4-442d-88f8-6cb2fb9f9101",
    "_uuid": "0fe1de012691c4da71e4b5dc9324204bd61cebae"
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d85b3f5-d900-4889-92f3-23cb539f6ed9",
    "_uuid": "eb674379b6d9312560f7b8bbc9d87da457f3d181"
   },
   "source": [
    "## 6-4) Cross Entropy\n",
    "Before this, you have to know **How Linear Regression Works**\n",
    "* Linear Regression: Draw a random line to find the **mean square root error** and find the slope and intercept to minimize this value (reduce the error to the minimum)\n",
    "* Since Logits is also linear equation, you have to find minimum cost!\n",
    "\n",
    "![Imgur](https://machinelearningblogcom.files.wordpress.com/2018/01/bildschirmfoto-2018-01-24-um-14-32-02.png?w=1400)\n",
    "\n",
    "For example, logits(we get above) is **red line**, and the real dataset is **blue dot**. \n",
    "1. For finding cost, you have to substract all blue dot value with red line. \n",
    "2. Next, You add all distance you find and get average. \n",
    "3. For good prediction, this average distance of red line & blue dot must be minimum value. \n",
    "\n",
    "* tf.nn.sigmoid_cross_entropy_with_logits(): for gradient_descent with sig results(hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4881aae2-320c-4af2-a243-41c11a8f0c34",
    "_uuid": "9f792f4ee5c1fdc31de05ca8d4bb68c600bba200"
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.sigmoid(logits)\n",
    "\n",
    "cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "# cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "980d8382-b7b7-44ad-8b0e-cd13b2d2f149",
    "_uuid": "c2965cd1421afd8e83fc8596a34298e7be5c7e15"
   },
   "source": [
    "## 6-5) Gradient Descent Optimizer\n",
    "\n",
    "![Imgur](http://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_gradient_descent_1.png)\n",
    "\n",
    "* GradientDescentOptimizer: It makes the best result with the least error\n",
    "* There are lots of optimizer methods provided in tensorflow. (GradientDescent, Adam, RMSProp, etc.)\n",
    "* learning rate : It indicates the degree of descending size.\n",
    "\n",
    "![Imgur](https://pbs.twimg.com/media/DK26ibcXUAEOwel.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aadf51d1-b5dc-49f5-991c-45ca6ae0ecb2",
    "_uuid": "eebe65b3e3633ec738b05288d549ec9e4d13014c"
   },
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "940eb4ef-6f9e-41ed-b692-c4d1d244dfec",
    "_uuid": "df417da0731dabafabe0119275f83d7cb1126641"
   },
   "source": [
    "## 6-6) Compare : original vs. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4984c760-fb34-45cf-82d6-6862438ab466",
    "_uuid": "26d175949daff82bd0a08115dd8600b1976f795e"
   },
   "outputs": [],
   "source": [
    "prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "correct_prediction = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84fdb2ef-75a6-462c-8688-146e546554a9",
    "_uuid": "ebec32f59831eb056d33d9231d3310122e4a82bb"
   },
   "source": [
    "## 6-7) Activate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b49eb9b5-3381-4fae-a042-d0ca1d722e3a",
    "_uuid": "05ecab0b5cc0c38ec015c2e5d66f9901b71ca463"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: train_x, Y: train_y})\n",
    "        if step % 1000 == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: train_x, Y: train_y})\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "            \n",
    "    train_acc = sess.run(accuracy, feed_dict={X: train_x, Y: train_y})\n",
    "    test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: test_x, Y: test_y})\n",
    "    print(\"Model Prediction =\", train_acc)\n",
    "    print(\"Test Prediction =\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "730a62f0-ff6f-4c85-b8d3-d2d75c98595f",
    "_uuid": "7cfedba0c43751afcc1c3b783307ea3a3e1d7734"
   },
   "source": [
    "---\n",
    "\n",
    "# 7. ANN Model Summary & Compare\n",
    "## 7-1) ANN - SLP Model\n",
    "* train_x, test_x : normalization data\n",
    "* 30 features\n",
    "* train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64fe8680-42d7-463e-a6e9-12a9bb0cb48e",
    "_uuid": "bc07298da8f7fca38547a9ac23a7854e80fe390e"
   },
   "outputs": [],
   "source": [
    "def ann_slp():\n",
    "    print(\"===========Data Summary===========\")\n",
    "    print(\"Training Data :\", train_x.shape)\n",
    "    print(\"Testing Data :\", test_x.shape)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None,30])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    W = tf.Variable(tf.random_normal([30,1], seed=0), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([1], seed=0), name='bias')\n",
    "\n",
    "    logits = tf.matmul(X,W) + b\n",
    "    hypothesis = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    correct_prediction = tf.equal(prediction, Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "    print(\"\\n============Processing============\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(10001):\n",
    "            sess.run(train, feed_dict={X: train_x, Y: train_y})\n",
    "            if step % 1000 == 0:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={X: train_x, Y: train_y})\n",
    "                print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: train_x, Y: train_y})\n",
    "        test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: test_x, Y: test_y})\n",
    "        \n",
    "        print(\"\\n============Results============\")\n",
    "        print(\"Model Prediction =\", train_acc)\n",
    "        print(\"Test Prediction =\", test_acc)\n",
    "        \n",
    "        return train_acc,test_acc\n",
    "    \n",
    "ann_slp_train_acc, ann_slp_test_acc = ann_slp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a79243a1-2d1c-48bc-8dca-6cb767ea96ab",
    "_uuid": "2d2f7824ba47035a65ad3024a912f8ac6be3e65d"
   },
   "source": [
    "## 7-2) ANN - SLP - PCA Model\n",
    "* pca_train_x, pca_test_x : normalization, PCA\n",
    "* 30 -> 10 features\n",
    "* train_y, test_y : we can use the same data as above activation values, since there are no changes in y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6aae88b-c03c-49f9-867f-c29e218499cd",
    "_uuid": "c19d3c5ff404d1ac5d20dbe05322adfaf103f6e0"
   },
   "outputs": [],
   "source": [
    "def ann_slp_pca():\n",
    "    sklearn_pca = sklearnPCA(n_components=10)\n",
    "\n",
    "    print(\"===========Data Summary===========\")\n",
    "    pca_train_x = sklearn_pca.fit_transform(train_x)\n",
    "    print(\"PCA Training Data :\", pca_train_x.shape)\n",
    "\n",
    "    pca_test_x = sklearn_pca.fit_transform(test_x)\n",
    "    print(\"PCA Testing Data :\", pca_test_x.shape)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None,10])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    W = tf.Variable(tf.random_normal([10,1], seed=0), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([1], seed=0), name='bias')\n",
    "\n",
    "    logits = tf.matmul(X,W) + b\n",
    "    hypothesis = tf.nn.sigmoid(logits)\n",
    "\n",
    "    cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost)\n",
    "\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    correct_prediction = tf.equal(prediction, Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "    print(\"\\n============Processing============\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(10001):\n",
    "            sess.run(train, feed_dict={X: pca_train_x, Y: train_y})\n",
    "            if step % 1000 == 0:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={X: pca_train_x, Y: train_y})\n",
    "                print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: pca_train_x, Y: train_y})\n",
    "        test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: pca_test_x, Y: test_y})\n",
    "        \n",
    "        print(\"\\n============Results============\")\n",
    "        print(\"PCA Model Prediction =\", train_acc)\n",
    "        print(\"PCA Test Prediction =\", test_acc)\n",
    "        \n",
    "        return train_acc, test_acc\n",
    "    \n",
    "ann_slp_pca_train_acc, ann_slp_pca_test_acc = ann_slp_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24c5639d-77ba-4a22-add1-a9fa75310d69",
    "_uuid": "f532469f3c320cf774d41972d177bb3d52219b80"
   },
   "source": [
    "## 7-3) ANN - MLP Model\n",
    "* train_x, test_x : normalization data\n",
    "* 30 features\n",
    "* train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3fde2a00-71cc-401e-81d5-102916b200f4",
    "_uuid": "11280c554427605e611ef9880fef6dc68306e587"
   },
   "outputs": [],
   "source": [
    "def ann_mlp():\n",
    "    print(\"===========Data Summary===========\")\n",
    "    print(\"Training Data :\", train_x.shape)\n",
    "    print(\"Testing Data :\", test_x.shape)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None,30])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # input\n",
    "    W1 = tf.Variable(tf.random_normal([30,60], seed=0), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([60], seed=0), name='bias1')\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "    # hidden1\n",
    "    W2 = tf.Variable(tf.random_normal([60,60], seed=0), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([60], seed=0), name='bias2')\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "    # hidden2\n",
    "    W3 = tf.Variable(tf.random_normal([60,90], seed=0), name='weight3')\n",
    "    b3 = tf.Variable(tf.random_normal([90], seed=0), name='bias3')\n",
    "    layer3 = tf.nn.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "    # output\n",
    "    W4 = tf.Variable(tf.random_normal([90,1], seed=0), name='weight4')\n",
    "    b4 = tf.Variable(tf.random_normal([1], seed=0), name='bias4')\n",
    "    logits = tf.matmul(layer3,W4) + b4\n",
    "    hypothesis = tf.nn.sigmoid(logits)\n",
    "\n",
    "    cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    correct_prediction = tf.equal(prediction, Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "    print(\"\\n============Processing============\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(10001):\n",
    "            sess.run(train, feed_dict={X: train_x, Y: train_y})\n",
    "            if step % 1000 == 0:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={X: train_x, Y: train_y})\n",
    "                print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: train_x, Y: train_y})\n",
    "        test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: test_x, Y: test_y})\n",
    "        \n",
    "        print(\"\\n============Results============\")\n",
    "        print(\"Model Prediction =\", train_acc)\n",
    "        print(\"Test Prediction =\", test_acc)\n",
    "        \n",
    "        return train_acc,test_acc\n",
    "    \n",
    "ann_mlp_train_acc, ann_mlp_test_acc = ann_mlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "30314455-9b3d-44f9-a93c-20d4baa077ba",
    "_uuid": "856f2fb5c12efc001d684524f4be819ce5ba733b"
   },
   "source": [
    "## 7-4) ANN - MLP - PCA Model\n",
    "* pca_train_x, pca_test_x : normalization, PCA\n",
    "* 30 -> 10 features\n",
    "* train_y, test_y : we can use the same data as above activation values, since there are no changes in y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0c782ad-7c50-4dfb-b0b2-80f30ff1797e",
    "_uuid": "65eea8735248469cd087b3f9b7c8c15e1614a702"
   },
   "outputs": [],
   "source": [
    "def ann_mlp_pca():\n",
    "    sklearn_pca = sklearnPCA(n_components=10)\n",
    "\n",
    "    print(\"===========Data Summary===========\")\n",
    "    pca_train_x = sklearn_pca.fit_transform(train_x)\n",
    "    print(\"PCA Training Data :\", pca_train_x.shape)\n",
    "\n",
    "    pca_test_x = sklearn_pca.fit_transform(test_x)\n",
    "    print(\"PCA Testing Data :\", pca_test_x.shape)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None,10])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # input\n",
    "    W1 = tf.Variable(tf.random_normal([10,64], seed=0), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([64], seed=0), name='bias1')\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "    # hidden1\n",
    "    W2 = tf.Variable(tf.random_normal([64,128], seed=0), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([128], seed=0), name='bias2')\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "    # hidden2\n",
    "    W3 = tf.Variable(tf.random_normal([128,128], seed=0), name='weight3')\n",
    "    b3 = tf.Variable(tf.random_normal([128], seed=0), name='bias3')\n",
    "    layer3 = tf.nn.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "    # output\n",
    "    W4 = tf.Variable(tf.random_normal([128,1], seed=0), name='weight4')\n",
    "    b4 = tf.Variable(tf.random_normal([1], seed=0), name='bias4')\n",
    "    logits = tf.matmul(layer3,W4) + b4\n",
    "    hypothesis = tf.nn.sigmoid(logits)\n",
    "\n",
    "    cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    correct_prediction = tf.equal(prediction, Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "    print(\"\\n============Processing============\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(10001):\n",
    "            sess.run(train, feed_dict={X: pca_train_x, Y: train_y})\n",
    "            if step % 1000 == 0:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={X: pca_train_x, Y: train_y})\n",
    "                print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: pca_train_x, Y: train_y})\n",
    "        test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: pca_test_x, Y: test_y})\n",
    "        \n",
    "        print(\"\\n============Results============\")\n",
    "        print(\"PCA Model Prediction =\", train_acc)\n",
    "        print(\"PCA Test Prediction =\", test_acc)\n",
    "        \n",
    "        return train_acc,test_acc\n",
    "        \n",
    "ann_mlp_pca_train_acc, ann_mlp_pca_test_acc = ann_mlp_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "087d207b-d75a-47bf-aecd-913153b1c59e",
    "_uuid": "abc120b032cc54ecf5a7e0c31f6a8711cbd8eab8"
   },
   "source": [
    "---\n",
    "\n",
    "# 8. Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2196f18-ab20-4ff2-bcc9-a4adbb7c329d",
    "_uuid": "75cf308f8477274a7fcf822c183ce7b806002378"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['Predict_Type'] = test_predict.astype(int)\n",
    "sub['Origin_Type'] = test_y\n",
    "sub['Correct'] = test_correct\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "052cbb93-69ff-447d-a7c6-fba5354e1cb0",
    "_uuid": "987dd2e5eb00eb28fd2d489b113aa9f67b5520b4"
   },
   "source": [
    "---\n",
    "\n",
    "# 9. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3b7dd25c-c74a-4ce5-9758-cbe85980acb2",
    "_uuid": "3bf8db7f51624347b485a3804622dd1a7ae2ae3b"
   },
   "outputs": [],
   "source": [
    "sub[['id','Predict_Type']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d67af6b4-c85b-4d31-a465-ae60ca7d8d61",
    "_uuid": "e4d3d7cefbb19a896c1a7355974aa6eb841be296"
   },
   "source": [
    "---\n",
    "\n",
    "# 10. Conclusion\n",
    "You can make your own ANN model with modifying **learning_rate, step range**.\n",
    "\n",
    "\n",
    "Planning : ANN-SLP with PCA, ANN-MLP\n",
    "\n",
    "Want to see my another kernels?\n",
    "\n",
    "* **Linear Regression(R ver.) [ How much will the premium be?](https://www.kaggle.com/mirichoi0218/regression-how-much-will-the-premium-be)**\n",
    "\n",
    "Upvotes and Comments are fully Welcomed :-)\n",
    "\n",
    "Thank you for watching!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
